{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04d05cae5f46444ba9ae6225274cab53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b214b85df5e4a338a3b3b0e34d556a7",
              "IPY_MODEL_cfbed53c8b1f4e3d94444af786a480e7",
              "IPY_MODEL_6ed2ca3d005246aaa2d39aa82b580f64"
            ],
            "layout": "IPY_MODEL_0da07e8d612c4422a9c1e2dd1850b949"
          }
        },
        "7b214b85df5e4a338a3b3b0e34d556a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_134d352c08b4455fbe21db3dbbac915e",
            "placeholder": "​",
            "style": "IPY_MODEL_6aa5588229bb42d2b48c0a8393495048",
            "value": "Loading weights: 100%"
          }
        },
        "cfbed53c8b1f4e3d94444af786a480e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e1c29ea41674d8185a1da24e5d0a117",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_11cb8fe8cae840fe8dbbd906ee5f3776",
            "value": 103
          }
        },
        "6ed2ca3d005246aaa2d39aa82b580f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c554d37408f643a8a5bb75e20c53d999",
            "placeholder": "​",
            "style": "IPY_MODEL_8c7dbbaaf1444b49affe502310f25139",
            "value": " 103/103 [00:00&lt;00:00, 459.92it/s, Materializing param=pooler.dense.weight]"
          }
        },
        "0da07e8d612c4422a9c1e2dd1850b949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134d352c08b4455fbe21db3dbbac915e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa5588229bb42d2b48c0a8393495048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e1c29ea41674d8185a1da24e5d0a117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11cb8fe8cae840fe8dbbd906ee5f3776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c554d37408f643a8a5bb75e20c53d999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c7dbbaaf1444b49affe502310f25139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "04d05cae5f46444ba9ae6225274cab53",
            "7b214b85df5e4a338a3b3b0e34d556a7",
            "cfbed53c8b1f4e3d94444af786a480e7",
            "6ed2ca3d005246aaa2d39aa82b580f64",
            "0da07e8d612c4422a9c1e2dd1850b949",
            "134d352c08b4455fbe21db3dbbac915e",
            "6aa5588229bb42d2b48c0a8393495048",
            "3e1c29ea41674d8185a1da24e5d0a117",
            "11cb8fe8cae840fe8dbbd906ee5f3776",
            "c554d37408f643a8a5bb75e20c53d999",
            "8c7dbbaaf1444b49affe502310f25139"
          ]
        },
        "id": "qiHWANp_arja",
        "outputId": "901b63fd-8e43-4365-b1c2-86ce205018c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================================================================\n",
            "[18:29:06] Hierarchical Inference (Planner DQN + Executive DQN) — Pretty Log\n",
            "==============================================================================\n",
            "[18:29:06] Device: cpu\n",
            "[18:29:06] Exec state dim: 194\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04d05cae5f46444ba9ae6225274cab53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18:29:08] Loaded sentence-transformers embedder for planner state.\n",
            "[18:29:08] Planner state dim: 1158\n",
            "[18:29:08] Loaded executive state_dict (strict match).\n",
            "[18:29:08] Loaded planner state_dict (strict match).\n",
            "\n",
            "==============================================================================\n",
            "[18:29:08] Hierarchical inference start\n",
            "==============================================================================\n",
            "[18:29:08] Query: write me a code for computing the third root of (a+b) ^ 2\n",
            "\n",
            "------------------------------------------------------------------------------\n",
            "[18:29:08] Executive: run subtasks (simulated LLM actions)\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "[18:29:08] Planner ⟶ I will ask the Executive to solve subtask:\n",
            "   compute_add_001\n",
            "[18:29:08] Executive ⟶ generate:\n",
            "   Producing candidate code...\n",
            "\n",
            "    def add(a: int, b: int) -> int:\n",
            "        return a + b\n",
            "[18:29:08] Executive ⟶ test:\n",
            "   Running unit tests for the generated code\n",
            "[18:29:08]    Test results: 3/3 passed\n",
            "[18:29:08] Executive ⟶ stop:\n",
            "   Episode finished for subtask\n",
            "\n",
            "[18:29:08] Planner ⟶ I will ask the Executive to solve subtask:\n",
            "   square_001\n",
            "[18:29:08] Executive ⟶ generate:\n",
            "   Producing candidate code...\n",
            "\n",
            "    def square(x: int) -> int:\n",
            "        return x ** 2\n",
            "[18:29:08] Executive ⟶ test:\n",
            "   Running unit tests for the generated code\n",
            "[18:29:08]    Test results: 3/3 passed\n",
            "[18:29:08] Executive ⟶ stop:\n",
            "   Episode finished for subtask\n",
            "\n",
            "[18:29:08] Planner ⟶ I will ask the Executive to solve subtask:\n",
            "   cbrt_001\n",
            "[18:29:08] Executive ⟶ generate:\n",
            "   Producing candidate code...\n",
            "\n",
            "    def cbrt(x: int) -> float:\n",
            "        if x == 0:\n",
            "            return 0\n",
            "        sign = -1 if x < 0 else 1\n",
            "        x_abs = abs(x)\n",
            "        r = round(x_abs ** (1.0 / 3.0))\n",
            "        if r ** 3 == x_abs:\n",
            "            return sign * r\n",
            "        return sign * (x_abs ** (1.0 / 3.0))\n",
            "[18:29:08] Executive ⟶ test:\n",
            "   Running unit tests for the generated code\n",
            "[18:29:08]    Test results: 4/4 passed\n",
            "[18:29:08] Executive ⟶ stop:\n",
            "   Episode finished for subtask\n",
            "\n",
            "------------------------------------------------------------------------------\n",
            "[18:29:08] Integration: combining helper functions into final compute()\n",
            "------------------------------------------------------------------------------\n",
            "[18:29:08] Integrated code assembled. Full content below:\n",
            "\n",
            "def add(a: int, b: int) -> int:\n",
            "    return a + b\n",
            "\n",
            "def square(x: int) -> int:\n",
            "    return x ** 2\n",
            "\n",
            "def cbrt(x: int) -> float:\n",
            "    if x == 0:\n",
            "        return 0\n",
            "    sign = -1 if x < 0 else 1\n",
            "    x_abs = abs(x)\n",
            "    r = round(x_abs ** (1.0 / 3.0))\n",
            "    if r ** 3 == x_abs:\n",
            "        return sign * r\n",
            "    return sign * (x_abs ** (1.0 / 3.0))\n",
            "\n",
            "def compute(a, b):\n",
            "    \"\"\"Compute the cube root of (a+b)^2 (i.e. (a+b)^(2/3)).\"\"\" \n",
            "    s = add(a, b)\n",
            "    s2 = square(s)\n",
            "    return cbrt(s2)\n",
            "\n",
            "\n",
            "------------------------------------------------------------------------------\n",
            "[18:29:08] Final Evaluation: validate integrated compute()\n",
            "------------------------------------------------------------------------------\n",
            "[18:29:08] TEST: compute(1,2) -> 2.080083823051904  expected ≈ 2.080083823051904  ok=True\n",
            "[18:29:08] TEST: compute(0,0) -> 0  expected ≈ 0.0  ok=True\n",
            "[18:29:08] TEST: compute(8,1) -> 4.3267487109222245  expected ≈ 4.3267487109222245  ok=True\n",
            "[18:29:08] TEST: compute(-1,8) -> 3.6593057100229713  expected ≈ 3.6593057100229713  ok=True\n",
            "[18:29:08] Final tests passed: 4/4\n",
            "\n",
            "==============================================================================\n",
            "[18:29:08] FINAL CODE (compute function only)\n",
            "==============================================================================\n",
            "\n",
            "def compute(a, b):\n",
            "    \"\"\"Compute the cube root of (a+b)^2 (i.e. (a+b)^(2/3)).\"\"\" \n",
            "    s = add(a, b)\n",
            "    s2 = square(s)\n",
            "    return cbrt(s2)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# load_and_run_hierarchical_inference_prettylog_final_compute_only.py\n",
        "# Same logic as your script; final output now prints ONLY the compute() function\n",
        "# and evaluation is separated from final code.\n",
        "\n",
        "import os, re, math, sys, time\n",
        "from typing import List, Dict\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# paths (adjust if your files are elsewhere)\n",
        "EXEC_MODEL_PATH = \"saved_models/dqn_dqfd_best.pt\"\n",
        "PLANNER_MODEL_PATH = \"saved_models/planner_dqn_best.pt\"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ---------------------------\n",
        "# Pretty logging helper (non-intrusive)\n",
        "# ---------------------------\n",
        "from datetime import datetime\n",
        "\n",
        "def now():\n",
        "    return datetime.now().strftime(\"%H:%M:%S\")\n",
        "\n",
        "def log_header(title):\n",
        "    print(\"\\n\" + \"=\"*78)\n",
        "    print(f\"[{now()}] {title}\")\n",
        "    print(\"=\"*78)\n",
        "\n",
        "def log_section(title):\n",
        "    print(\"\\n\" + \"-\"*78)\n",
        "    print(f\"[{now()}] {title}\")\n",
        "    print(\"-\"*78)\n",
        "\n",
        "def log_step(role, action, detail=None):\n",
        "    prefix = f\"[{now()}] {role} ⟶ {action}\"\n",
        "    if detail:\n",
        "        print(prefix + \":\")\n",
        "        for line in detail.splitlines():\n",
        "            print(\"   \" + line)\n",
        "    else:\n",
        "        print(prefix)\n",
        "\n",
        "def log_simple(*args, **kwargs):\n",
        "    print(*args, **kwargs)\n",
        "\n",
        "# initial header\n",
        "log_header(\"Hierarchical Inference (Planner DQN + Executive DQN) — Pretty Log\")\n",
        "log_simple(f\"[{now()}] Device: {device}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Recreate DuelingQNetwork exactly like training code\n",
        "# ---------------------------\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DuelingQNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden=[512,256], output_dim=4):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        prev = input_dim\n",
        "        for h in hidden:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev = h\n",
        "        self.trunk = nn.Sequential(*layers)\n",
        "        # **Important**: attribute names match training: value_head, adv_head\n",
        "        half = prev//2 if prev//2>0 else 32\n",
        "        self.value_head = nn.Sequential(\n",
        "            nn.Linear(prev, half),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(half, 1)\n",
        "        )\n",
        "        self.adv_head = nn.Sequential(\n",
        "            nn.Linear(prev, half),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(half, output_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        t = self.trunk(x)\n",
        "        v = self.value_head(t)\n",
        "        a = self.adv_head(t)\n",
        "        q = v + (a - a.mean(dim=1, keepdim=True))\n",
        "        return q\n",
        "\n",
        "# ---------------------------\n",
        "# Executive hash embedder (exact as training)\n",
        "# ---------------------------\n",
        "VOCAB_SIZE = 4096\n",
        "EMB_DIM = 64\n",
        "_rng = np.random.RandomState(42)\n",
        "_emb_table = _rng.normal(scale=0.5, size=(VOCAB_SIZE, EMB_DIM)).astype(np.float32)\n",
        "\n",
        "def _tokens_of(text: str):\n",
        "    if not text:\n",
        "        return []\n",
        "    return re.findall(r\"\\w+\", text.lower())\n",
        "\n",
        "def text_to_emb(text: str) -> np.ndarray:\n",
        "    toks = _tokens_of(text)\n",
        "    if not toks:\n",
        "        return np.zeros(EMB_DIM, dtype=np.float32)\n",
        "    ids = [abs(hash(t)) % VOCAB_SIZE for t in toks]\n",
        "    vecs = _emb_table[ids]\n",
        "    return vecs.mean(axis=0)\n",
        "\n",
        "def make_exec_state(task_prompt: str, last_code: str, last_test_feedback: str) -> np.ndarray:\n",
        "    t_emb = text_to_emb(task_prompt)\n",
        "    c_emb = text_to_emb(last_code or \"\")\n",
        "    f_emb = text_to_emb(last_test_feedback or \"\")\n",
        "    flags = np.array([1.0 if (last_code and last_code.strip()) else 0.0,\n",
        "                      1.0 if (last_test_feedback and last_test_feedback.strip()) else 0.0], dtype=np.float32)\n",
        "    return np.concatenate([t_emb, c_emb, f_emb, flags]).astype(np.float32)\n",
        "\n",
        "# compute exec state dim\n",
        "EXEC_STATE_DIM = make_exec_state(\"def foo():\\n\", \"\", \"\").shape[0]\n",
        "log_simple(f\"[{now()}] Exec state dim: {EXEC_STATE_DIM}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Planner embedder: try sentence-transformers like training, else fallback to hash-embedding\n",
        "# ---------------------------\n",
        "USE_SENTENCE_TRANSFORMER = True\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    embedder = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    def make_planner_state(prompt: str, last_code: str, last_test_feedback: str,\n",
        "                         has_planned: bool = False, executed_count: int = 0,\n",
        "                         integrated: bool = False, evaluated: bool = False,\n",
        "                         invalid_action: bool = False, last_test_passed: bool = False) -> np.ndarray:\n",
        "        task_emb = embedder.encode([prompt], show_progress_bar=False)[0]\n",
        "        code_emb = embedder.encode([last_code or \"\"], show_progress_bar=False)[0]\n",
        "        feedback_emb = embedder.encode([last_test_feedback or \"\"], show_progress_bar=False)[0]\n",
        "        flags = np.array([\n",
        "            1.0 if has_planned else 0.0,\n",
        "            float(executed_count),\n",
        "            1.0 if integrated else 0.0,\n",
        "            1.0 if evaluated else 0.0,\n",
        "            1.0 if invalid_action else 0.0,\n",
        "            1.0 if last_test_passed else 0.0,\n",
        "        ], dtype=np.float32)\n",
        "        return np.concatenate([task_emb, code_emb, feedback_emb, flags]).astype(np.float32)\n",
        "    log_simple(f\"[{now()}] Loaded sentence-transformers embedder for planner state.\")\n",
        "except Exception as e:\n",
        "    log_simple(f\"[{now()}] Could not load sentence-transformers (falling back). Reason: {e}\")\n",
        "    USE_SENTENCE_TRANSFORMER = False\n",
        "    # fallback uses same hash emb but repeated to approximate dims\n",
        "    def make_planner_state(prompt: str, last_code: str, last_test_feedback: str,\n",
        "                         has_planned: bool = False, executed_count: int = 0,\n",
        "                         integrated: bool = False, evaluated: bool = False,\n",
        "                         invalid_action: bool = False, last_test_passed: bool = False) -> np.ndarray:\n",
        "        t = text_to_emb(prompt)\n",
        "        c = text_to_emb(last_code or \"\")\n",
        "        f = text_to_emb(last_test_feedback or \"\")\n",
        "        flags = np.array([\n",
        "            1.0 if has_planned else 0.0,\n",
        "            float(executed_count),\n",
        "            1.0 if integrated else 0.0,\n",
        "            1.0 if evaluated else 0.0,\n",
        "            1.0 if invalid_action else 0.0,\n",
        "            1.0 if last_test_passed else 0.0,\n",
        "        ], dtype=np.float32)\n",
        "        # concatenate and repeat to make a larger vector (not ideal but functional)\n",
        "        return np.concatenate([t, c, f, flags]).astype(np.float32)\n",
        "\n",
        "# compute planner state dim\n",
        "PLANNER_STATE_DIM = make_planner_state(\"def foo():\", \"\", \"\").shape[0]\n",
        "log_simple(f\"[{now()}] Planner state dim: {PLANNER_STATE_DIM}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Instantiate networks with matching shapes\n",
        "# ---------------------------\n",
        "exec_qnet = DuelingQNetwork(EXEC_STATE_DIM, hidden=[512,256], output_dim=4).to(device)\n",
        "planner_qnet = DuelingQNetwork(PLANNER_STATE_DIM, hidden=[512,256], output_dim=5).to(device)\n",
        "\n",
        "def try_load(model, path, model_name=\"model\"):\n",
        "    if not os.path.exists(path):\n",
        "        log_simple(f\"[{now()}] ERROR: {model_name} checkpoint not found at {path}\")\n",
        "        return False\n",
        "    state = torch.load(path, map_location=device)\n",
        "    try:\n",
        "        model.load_state_dict(state)\n",
        "        log_simple(f\"[{now()}] Loaded {model_name} state_dict (strict match).\")\n",
        "        return True\n",
        "    except RuntimeError as e:\n",
        "        log_simple(f\"[{now()}] Strict load failed for {model_name}: {e}\")\n",
        "        # attempt non-strict load to see which keys mismatch but still load what we can\n",
        "        try:\n",
        "            model.load_state_dict(state, strict=False)\n",
        "            model_keys = set(model.state_dict().keys())\n",
        "            state_keys = set(state.keys())\n",
        "            missing = sorted(list(model_keys - state_keys))\n",
        "            unexpected = sorted(list(state_keys - model_keys))\n",
        "            if missing:\n",
        "                log_simple(f\"[{now()}] Keys in model but not in state (will be left as init): {missing}\")\n",
        "            if unexpected:\n",
        "                log_simple(f\"[{now()}] Keys in state but not in model: {unexpected}\")\n",
        "            log_simple(f\"[{now()}] Loaded {model_name} with strict=False (partial load).\")\n",
        "            return True\n",
        "        except Exception as e2:\n",
        "            log_simple(f\"[{now()}] Failed to load {model_name} even with strict=False: {e2}\")\n",
        "            return False\n",
        "\n",
        "ok1 = try_load(exec_qnet, EXEC_MODEL_PATH, \"executive\")\n",
        "ok2 = try_load(planner_qnet, PLANNER_MODEL_PATH, \"planner\")\n",
        "\n",
        "if not (ok1 and ok2):\n",
        "    log_section(\"Model load failure — aborting\")\n",
        "    log_simple(f\"[{now()}] One or both models failed to load cleanly. See messages above. Aborting run.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "exec_qnet.eval()\n",
        "planner_qnet.eval()\n",
        "\n",
        "# ---------------------------\n",
        "# Now perform the hierarchical inference (no training)\n",
        "# ---------------------------\n",
        "log_header(\"Hierarchical inference start\")\n",
        "QUERY = \"write me a code for computing the third root of (a+b) ^ 2\"\n",
        "log_simple(f\"[{now()}] Query: {QUERY}\")\n",
        "\n",
        "\n",
        "TASK_ADD = {\n",
        "    \"task_id\": \"compute_add_001\",\n",
        "    \"prompt\": \"def add(a: int, b: int) -> int:\\n    \\\"\\\"\\\"Return a + b.\\\"\\\"\\\"\\n\",\n",
        "    \"tests\": [\n",
        "        \"assert add(1,2) == 3\",\n",
        "        \"assert add(0,0) == 0\",\n",
        "        \"assert add(-1,2) == 1\",\n",
        "    ],\n",
        "    \"correct_code\": \"def add(a: int, b: int) -> int:\\n    return a + b\",\n",
        "    \"incorrect_code\": \"def add(a: int, b: int) -> int:\\n    return a - b\",\n",
        "    \"debugged_code\": \"def add(a: int, b: int) -> int:\\n    return a + b\"\n",
        "}\n",
        "\n",
        "TASK_SQUARE = {\n",
        "    \"task_id\": \"square_001\",\n",
        "    \"prompt\": \"def square(x: int) -> int:\\n    \\\"\\\"\\\"Return x squared.\\\"\\\"\\\"\\n\",\n",
        "    \"tests\": [\n",
        "        \"assert square(2) == 4\",\n",
        "        \"assert square(0) == 0\",\n",
        "        \"assert square(-3) == 9\",\n",
        "    ],\n",
        "    \"correct_code\": \"def square(x: int) -> int:\\n    return x ** 2\",\n",
        "    \"incorrect_code\": \"def square(x: int) -> int:\\n    return x * 2\",\n",
        "    \"debugged_code\": \"def square(x: int) -> int:\\n    return x ** 2\"\n",
        "}\n",
        "\n",
        "TASK_CBRT = {\n",
        "    \"task_id\": \"cbrt_001\",\n",
        "    \"prompt\": \"def cbrt(x: int) -> float:\\n    \\\"\\\"\\\"Return the real cube root of x. For perfect cubes return exact integer when possible.\\\"\\\"\\\"\\n\",\n",
        "    \"tests\": [\n",
        "        \"assert cbrt(27) == 3\",\n",
        "        \"assert cbrt(8) == 2\",\n",
        "        \"assert cbrt(0) == 0\",\n",
        "        \"assert cbrt(-27) == -3\",\n",
        "    ],\n",
        "    \"correct_code\": \"def cbrt(x: int) -> float:\\n    if x == 0:\\n        return 0\\n    sign = -1 if x < 0 else 1\\n    x_abs = abs(x)\\n    r = round(x_abs ** (1.0 / 3.0))\\n    if r ** 3 == x_abs:\\n        return sign * r\\n    return sign * (x_abs ** (1.0 / 3.0))\",\n",
        "    \"incorrect_code\": \"def cbrt(x: int) -> float:\\n    return x ** (1/3)\",\n",
        "    \"debugged_code\": \"def cbrt(x: int) -> float:\\n    if x == 0:\\n        return 0\\n    sign = -1 if x < 0 else 1\\n    x_abs = abs(x)\\n    r = round(x_abs ** (1.0 / 3.0))\\n    if r ** 3 == x_abs:\\n        return sign * r\\n    return sign * (x_abs ** (1.0 / 3.0))\"\n",
        "}\n",
        "\n",
        "SUBTASKS = [TASK_ADD, TASK_SQUARE, TASK_CBRT]\n",
        "\n",
        "# Executive simulation: run generate->test->stop for each subtask using correct_code\n",
        "log_section(\"Executive: run subtasks (simulated LLM actions)\")\n",
        "produced = {}\n",
        "for t in SUBTASKS:\n",
        "    log_simple(\"\")\n",
        "    log_step(\"Planner\", \"I will ask the Executive to solve subtask\", t[\"task_id\"])\n",
        "    # generate\n",
        "    log_step(\"Executive\", \"generate\", \"Producing candidate code...\")\n",
        "    gen_code = t[\"correct_code\"]  # we use the provided correct code (simulated LLM)\n",
        "    print()\n",
        "    for line in gen_code.splitlines():\n",
        "        print(\"    \" + line)\n",
        "    # test\n",
        "    log_step(\"Executive\", \"test\", \"Running unit tests for the generated code\")\n",
        "    # run tests in a safe exec environment\n",
        "    exec_globals = {}\n",
        "    try:\n",
        "        exec(\"from typing import List\", exec_globals)\n",
        "        exec(gen_code, exec_globals)\n",
        "        passed = True\n",
        "        passed_count = 0\n",
        "        for test in t[\"tests\"]:\n",
        "            try:\n",
        "                exec(test, exec_globals)\n",
        "                passed_count += 1\n",
        "            except Exception as e:\n",
        "                passed = False\n",
        "                log_simple(f\"[{now()}]    Test failed: {test} -> {repr(e)}\")\n",
        "        log_simple(f\"[{now()}]    Test results: {passed_count}/{len(t['tests'])} passed\")\n",
        "    except Exception as e:\n",
        "        log_simple(f\"[{now()}]    Error during generation or test execution: {e}\")\n",
        "        passed = False\n",
        "    # stop\n",
        "    log_step(\"Executive\", \"stop\", \"Episode finished for subtask\")\n",
        "    produced[t[\"task_id\"]] = gen_code\n",
        "\n",
        "# Integration: combine helpers into compute function\n",
        "log_section(\"Integration: combining helper functions into final compute()\")\n",
        "integrated = \"\\n\\n\".join([produced[\"compute_add_001\"], produced[\"square_001\"], produced[\"cbrt_001\"]]) + \"\"\"\n",
        "\n",
        "def compute(a, b):\n",
        "    \\\"\\\"\\\"Compute the cube root of (a+b)^2 (i.e. (a+b)^(2/3)).\\\"\\\"\\\"\n",
        "    s = add(a, b)\n",
        "    s2 = square(s)\n",
        "    return cbrt(s2)\n",
        "\"\"\"\n",
        "# print the full integrated code (no truncation)\n",
        "log_simple(f\"[{now()}] Integrated code assembled. Full content below:\\n\")\n",
        "print(integrated)\n",
        "\n",
        "# Final evaluation: executive receives integrated code as last generated code, then test\n",
        "log_section(\"Final Evaluation: validate integrated compute()\")\n",
        "exec_globals = {}\n",
        "final_ok = False\n",
        "try:\n",
        "    exec(\"import math\\nfrom typing import List\", exec_globals)\n",
        "    exec(integrated, exec_globals)\n",
        "    # run planner tests from earlier planner training (we use the planner task tests you provided in planner)\n",
        "    final_tests = [\n",
        "        (\"compute(1,2)\", (1+2)**(2/3)),\n",
        "        (\"compute(0,0)\", (0+0)**(2/3)),\n",
        "        (\"compute(8,1)\", (8+1)**(2/3)),\n",
        "        (\"compute(-1,8)\", (-1+8)**(2/3)),\n",
        "    ]\n",
        "    ok_count = 0\n",
        "    for expr, expected in final_tests:\n",
        "        try:\n",
        "            out = eval(expr, exec_globals)\n",
        "            is_ok = math.isclose(out, expected, rel_tol=1e-9)\n",
        "            log_simple(f\"[{now()}] TEST: {expr} -> {out}  expected ≈ {expected}  ok={is_ok}\")\n",
        "            if is_ok: ok_count += 1\n",
        "        except Exception as e:\n",
        "            log_simple(f\"[{now()}] TEST: {expr} -> ERROR: {e}\")\n",
        "    log_simple(f\"[{now()}] Final tests passed: {ok_count}/{len(final_tests)}\")\n",
        "    final_ok = (ok_count == len(final_tests))\n",
        "except Exception as e:\n",
        "    log_simple(f\"[{now()}] Error during final integration/eval: {e}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Print final code delivered to user: ONLY the compute() function (no helpers)\n",
        "# and separated from evaluation logs\n",
        "# ---------------------------\n",
        "print(\"\\n\" + \"=\"*78)\n",
        "print(f\"[{now()}] FINAL CODE (compute function only)\")\n",
        "print(\"=\"*78 + \"\\n\")\n",
        "\n",
        "compute_only = \"\"\"def compute(a, b):\n",
        "    \\\"\\\"\\\"Compute the cube root of (a+b)^2 (i.e. (a+b)^(2/3)).\\\"\\\"\\\"\n",
        "    s = add(a, b)\n",
        "    s2 = square(s)\n",
        "    return cbrt(s2)\n",
        "\"\"\"\n",
        "print(compute_only)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QVzzjiGHbYbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}